{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first task is to use a Gaussian model to detect if an unlabeled example from a data set should be considered an anomaly. We have a simple 2-dimensional data set to start off with so we can easily visualize what the algorithm is doing. Let's pull in and plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy.io import loadmat\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('data/ex8data1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 2)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAHVCAYAAADl4K3UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bde67f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(X[:,0], X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there's a pretty tight cluster in the center with several values further out away from the cluster. In this simple example, these could be considered anomalies. To find out, we're tasked with estimating a Gaussian distribution for each feature in the data. You may recall that to define a probability distribution we need two things - mean and variance. To accomplish this we'll create a simple function that calculates the mean and variance for each feature in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gaussian(X):\n",
    "    mu = X.mean(axis=0)\n",
    "    sigma = X.var(axis=0)\n",
    "    \n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = estimate_gaussian(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 14.11222578,  14.99771051]), array([ 1.83263141,  1.70974533]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model parameters, we need to determine a probability threshold which indicates that an example should be considered an anomaly. To do this, we need to use a set of labeled validation data (where the true anomalies have been marked for us) and test the model's performance at identifying those anomalies given different threshold values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval = data['Xval']\n",
    "yval = data['yval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307, 2), (307, 1))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval.shape, yval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a way to calculate the probability that a data point belongs to a normal distribution given some set of parameters. Fortunately SciPy has this built-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = stats.norm(mu[0], sigma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.183842  ,  0.20221694,  0.21746136,  0.19778763,  0.20858956,\n",
       "        0.21652359,  0.16991291,  0.15123542,  0.1163989 ,  0.1594734 ,\n",
       "        0.21716057,  0.21760472,  0.20141857,  0.20157497,  0.21711385,\n",
       "        0.21758775,  0.21695576,  0.2138258 ,  0.21057069,  0.1173018 ,\n",
       "        0.20765108,  0.21717452,  0.19510663,  0.21702152,  0.17429399,\n",
       "        0.15413455,  0.21000109,  0.20223586,  0.21031898,  0.21313426,\n",
       "        0.16158946,  0.2170794 ,  0.17825767,  0.17414633,  0.1264951 ,\n",
       "        0.19723662,  0.14538809,  0.21766361,  0.21191386,  0.21729442,\n",
       "        0.21238912,  0.18799417,  0.21259798,  0.21752767,  0.20616968,\n",
       "        0.21520366,  0.1280081 ,  0.21768113,  0.21539967,  0.16913173])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.pdf(X[:,0])[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case it isn't clear, we just calculated the probability that each of the first 50 instances of our data set's first dimension belong to the distribution that we defined earlier by calculating the mean and variance for that dimension. Essentially it's computing how far each instance is from the mean and how that compares to the \"typical\" distance from the mean for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute and save the probability density of each of the values in our data set given the Gaussian model parameters we calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.zeros((X.shape[0], X.shape[1]))\n",
    "p[:,0] = stats.norm(mu[0], sigma[0]).pdf(X[:,0])\n",
    "p[:,1] = stats.norm(mu[1], sigma[1]).pdf(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 2)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to do this for the validation set (using the same model parameters). We'll use these probabilities combined with the true label to determine the optimal probability threshold to assign data points as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = np.zeros((X.shape[0], X.shape[1]))\n",
    "pval[:,0] = stats.norm(mu[0], sigma[0]).pdf(Xval[:,0])\n",
    "pval[:,1] = stats.norm(mu[1], sigma[1]).pdf(Xval[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a function that finds the best threshold value given the probability density values and true labels. To do this we'll calculate the F1 score for varying values of epsilon. F1 is a function of the number of true positives, false positives, and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_threshold(pval,yval):\n",
    "    best_epsilon = 0\n",
    "    best_f1 = 0\n",
    "    f1 = 0\n",
    "    \n",
    "    step = (pval.max() - pval.min())/1000\n",
    "    \n",
    "    for epsilon in np.arange(pval.min(), pval.max(), step):\n",
    "        preds = pval < epsilon\n",
    "        \n",
    "        tp = np.sum(np.logical_and(preds == 1, yval == 1)).astype(float)\n",
    "        fp = np.sum(np.logical_and(preds == 1, yval == 0)).astype(float)\n",
    "        fn = np.sum(np.logical_and(preds == 0, yval == 1)).astype(float)\n",
    "        \n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2* precision * recall) / (precision + recall)\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_epsilon = epsilon\n",
    "            \n",
    "    return best_epsilon, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "epsilon, f1 = select_threshold(pval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0095667060059568421, 0.7142857142857143)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can apply the threshold to the data set and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAHVCAYAAAAU6/ZZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105ec9a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# indexes of values considered to be outliers\n",
    "outliers = np.where(p < epsilon)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(X[:,0], X[:,1])\n",
    "ax.scatter(X[outliers[0],0], X[outliers[0],1], s=50, color='r', marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points in red are the ones that were flagged as outliers. Visually these seem pretty reasonable. The top right point that has some separation (but was not flagged) may be an outlier too, but it's fairly close. There's another example in the text of applying this to a higher-dimensional data set, but since it's a trivial extension of the two-dimensional example we'll move on to the last section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation engines use item and user-based similarity measures to examine a user's historical preferences to make recommendations for new \"things\" the user might be interested in. In this exercise we'll implement a particular recommendation algorithm called collaborative filtering and apply it to a data set of movie ratings. Let's first load and examine the data we'll be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R': array([[1, 1, 0, ..., 1, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 1],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'Y': array([[5, 4, 0, ..., 5, 0, 0],\n",
       "        [3, 0, 0, ..., 0, 0, 5],\n",
       "        [4, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " '__globals__': [],\n",
       " '__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Thu Dec  1 17:19:26 2011',\n",
       " '__version__': '1.0'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat('data/ex8_movies.mat')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y is a (number of movies x number of users) array containing ratings from 1 to 5. R is an \"indicator\" array containing binary values indicating if a user has rated a movie or not. Both should have the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1682, 943), (1682, 943))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data['Y']\n",
    "R = data['R']\n",
    "Y.shape, R.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the average rating for a movie by averaging over a row in Y for indexes where a rating is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5832449628844114"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[1,R[1,:]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we're going to implement a cost function for collaborative filtering. Intuitively, the \"cost\" is the degree to which a set of movie rating predictions deviate from the true predictions. The cost equation is given in the exercise text. It is based on two sets of parameter matrices called X and Theta in the text. These are \"unrolled\" into the \"params\" input so that we can use SciPy's optimization package later on. Note that I've included the array/matrix shapes in comments to help illustrate how the matrix interactions work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, Y, R, num_features):\n",
    "    Y = np.matrix(Y) # (1682, 943)\n",
    "    R = np.matrix(R) # (1682, 943)\n",
    "    num_movies = Y.shape[0]\n",
    "    num_users = Y.shape[1]\n",
    "    \n",
    "    #reshape the parameter array into parameter matrices\n",
    "    X = np.matrix(np.reshape(params[:num_movies * num_features], (num_movies, num_features))) # (1682,10)\n",
    "    Theta = np.matrix(np.reshape(params[num_movies * num_features:], (num_users, num_features)))# (943, 10)\n",
    "    \n",
    "    #initialise\n",
    "    J = 0\n",
    "    \n",
    "    error = np.multiply((X * Theta.T) - Y, R) # (1682, 943)\n",
    "    squared_error = np.power(error, 2) # (1682, 943)\n",
    "    J = (1. / 2) * np.sum(squared_error)\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test this, we're provided with a set of pre-trained parameters that we can evaluate. To keep the evaluation time down, we'll look at just a small sub-set of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.224603725685675"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = 4\n",
    "movies = 5\n",
    "features = 3\n",
    "\n",
    "params_data = loadmat('data/ex8_movieParams.mat')\n",
    "X = params_data['X']\n",
    "Theta = params_data['Theta']\n",
    "\n",
    "X_sub = X[:movies, :features]\n",
    "Theta_sub = Theta[:users,:features]\n",
    "Y_sub = Y[:movies, :users]\n",
    "R_sub = R[:movies, :users]\n",
    "\n",
    "params = np.concatenate((np.ravel(X_sub), np.ravel(Theta_sub)))\n",
    "\n",
    "cost(params, Y_sub, R_sub, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This answer matches what the exercise text said we're supposed to get. Next we need to implement the gradient computations. Just like we did with the neural networks implementation in exercise 4, we'll extend the cost function to also compute the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, Y, R, num_features):\n",
    "    Y = np.matrix(Y) # (1682, 943)\n",
    "    R = np.matrix(R) # (1682, 943)\n",
    "    num_movies = Y.shape[0]\n",
    "    num_users = Y.shape[1]\n",
    "    \n",
    "    #reshape the parameter array into parameter matrices\n",
    "    X = np.matrix(np.reshape(params[:num_movies * num_features], (num_movies, num_features))) # (1682,10)\n",
    "    Theta = np.matrix(np.reshape(params[num_movies * num_features:], (num_users, num_features)))# (943, 10)\n",
    "    \n",
    "    #initialise\n",
    "    J = 0\n",
    "    X_grad = np.zeros(X.shape) # (1682, 10)\n",
    "    Theta_grad = np.zeros(Theta.shape) # (943, 10)\n",
    "    \n",
    "    #compute cost\n",
    "    error = np.multiply((X * Theta.T) - Y, R) # (1682, 943)\n",
    "    squared_error = np.power(error, 2) # (1682, 943)\n",
    "    J = (1. / 2) * np.sum(squared_error)\n",
    "    \n",
    "    #calcualte the gradients\n",
    "    X_grad = error * Theta\n",
    "    Theta_grad = error.T  * X\n",
    "    \n",
    "    #unravel the gradient matrixes into single array\n",
    "    grad = np.concatenate((np.ravel(X_grad), np.ravel(Theta_grad)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "J, grad = cost(params, Y_sub, R_sub, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.224603725685675,\n",
       " array([ -2.52899165,   7.57570308,  -1.89979026,  -0.56819597,\n",
       "          3.35265031,  -0.52339845,  -0.83240713,   4.91163297,\n",
       "         -0.76677878,  -0.38358278,   2.26333698,  -0.35334048,\n",
       "         -0.80378006,   4.74271842,  -0.74040871, -10.5680202 ,\n",
       "          4.62776019,  -7.16004443,  -3.05099006,   1.16441367,\n",
       "         -3.47410789,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to add regularization to both the cost and gradient calculations. We'll create one final regularized version of the function (note that this version includes an additional learning rate parameter called \"lambda\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, Y, R, num_features, learning_rate):  \n",
    "    Y = np.matrix(Y)  # (1682, 943)\n",
    "    R = np.matrix(R)  # (1682, 943)\n",
    "    num_movies = Y.shape[0]\n",
    "    num_users = Y.shape[1]\n",
    "\n",
    "    # reshape the parameter array into parameter matrices\n",
    "    X = np.matrix(np.reshape(params[:num_movies * num_features], (num_movies, num_features)))  # (1682, 10)\n",
    "    Theta = np.matrix(np.reshape(params[num_movies * num_features:], (num_users, num_features)))  # (943, 10)\n",
    "\n",
    "    # initializations\n",
    "    J = 0\n",
    "    X_grad = np.zeros(X.shape)  # (1682, 10)\n",
    "    Theta_grad = np.zeros(Theta.shape)  # (943, 10)\n",
    "\n",
    "    # compute the cost\n",
    "    error = np.multiply((X * Theta.T) - Y, R)  # (1682, 943)\n",
    "    squared_error = np.power(error, 2)  # (1682, 943)\n",
    "    J = (1. / 2) * np.sum(squared_error)\n",
    "\n",
    "    # add the cost regularization\n",
    "    J = J + ((learning_rate / 2) * np.sum(np.power(Theta, 2)))\n",
    "    J = J + ((learning_rate / 2) * np.sum(np.power(X, 2)))\n",
    "\n",
    "    # calculate the gradients with regularization\n",
    "    X_grad = (error * Theta) + (learning_rate * X)\n",
    "    Theta_grad = (error.T * X) + (learning_rate * Theta)\n",
    "\n",
    "    # unravel the gradient matrices into a single array\n",
    "    grad = np.concatenate((np.ravel(X_grad), np.ravel(Theta_grad)))\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "J, grad = cost(params, Y_sub, R_sub, features, 1.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.344056244274221,\n",
       " array([ -0.95596339,   6.97535514,  -0.10861109,   0.60308088,\n",
       "          2.77421145,   0.25839822,   0.12985616,   4.0898522 ,\n",
       "         -0.89247334,   0.29684395,   1.06300933,   0.66738144,\n",
       "          0.60252677,   4.90185327,  -0.19747928, -10.13985478,\n",
       "          2.10136256,  -6.76563628,  -2.29347024,   0.48244098,\n",
       "         -2.99791422,  -0.64787484,  -0.71820673,   1.27006666,\n",
       "          1.09289758,  -0.40784086,   0.49026541]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result again matches up with the expected output from the exercise code, so it looks like the regularization is working. Before we train the model, we have one final step. We're tasked with creating our own movie ratings so we can use the model to generate personalized recommendations. A file is provided for us that links the movie index to its title. Let's load the file into a dictionary and use some sample ratings provided in the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_idx = {}\n",
    "f = open('data/movie_ids.txt', encoding='latin1')\n",
    "for line in f:\n",
    "    tokens = line.split(' ')\n",
    "    tokens[-1] = tokens[-1][:-1]\n",
    "    movie_idx[int(tokens[0]) -1] = ' '.join(tokens[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.zeros((1682,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[0] = 4  \n",
    "ratings[6] = 3  \n",
    "ratings[11] = 5  \n",
    "ratings[53] = 4  \n",
    "ratings[63] = 5  \n",
    "ratings[65] = 3  \n",
    "ratings[68] = 5  \n",
    "ratings[97] = 2  \n",
    "ratings[182] = 4  \n",
    "ratings[225] = 5  \n",
    "ratings[354] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rated Toy Story (1995) with 4 stars.\n",
      "Rated Twelve Monkeys (1995) with 3 stars.\n",
      "Rated Usual Suspects, The (1995) with 5 stars.\n",
      "Rated Outbreak (1995) with 4 stars.\n",
      "Rated Shawshank Redemption, The (1994) with 5 stars.\n",
      "Rated While You Were Sleeping (1995) with 3 stars.\n",
      "Rated Forrest Gump (1994) with 5 stars.\n",
      "Rated Silence of the Lambs, The (1991) with 2 stars.\n",
      "Rated Alien (1979) with 4 stars.\n",
      "Rated Die Hard 2 (1990) with 5 stars.\n",
      "Rated Sphere (1998) with 5 stars.\n"
     ]
    }
   ],
   "source": [
    "print('Rated {0} with {1} stars.'.format(movie_idx[0], str(int(ratings[0]))))  \n",
    "print('Rated {0} with {1} stars.'.format(movie_idx[6], str(int(ratings[6]))))  \n",
    "print('Rated {0} with {1} stars.'.format(movie_idx[11], str(int(ratings[11]))))  \n",
    "print('Rated {0} with {1} stars.'.format(movie_idx[53], str(int(ratings[53]))))  \n",
    "print('Rated {0} with {1} stars.'.format(movie_idx[63], str(int(ratings[63]))))  \n",
    "print('Rated {0} with {1} stars.'.format(movie_idx[65], str(int(ratings[65]))))  \n",
    "print('Rated {0} with {1} stars.'.format(movie_idx[68], str(int(ratings[68]))))  \n",
    "print('Rated {0} with {1} stars.'.format(movie_idx[97], str(int(ratings[97]))))  \n",
    "print('Rated {0} with {1} stars.'.format(movie_idx[182], str(int(ratings[182]))))  \n",
    "print('Rated {0} with {1} stars.'.format(movie_idx[225], str(int(ratings[225]))))  \n",
    "print('Rated {0} with {1} stars.'.format(movie_idx[354], str(int(ratings[354]))))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add this custom ratings vector to the data set so it gets included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = data['R']\n",
    "Y = data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.append(Y, ratings, axis=1)\n",
    "R = np.append(R, ratings !=0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to train the collaborative filtering model. We're going to normalize the ratings and then run the optimization routine using our cost function, parameter vector, and data matrices at inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = Y.shape[0]  \n",
    "users = Y.shape[1]  \n",
    "features = 10  \n",
    "learning_rate = 10.\n",
    "\n",
    "X = np.random.random(size=(movies, features))  \n",
    "Theta = np.random.random(size=(users, features))  \n",
    "params = np.concatenate((np.ravel(X), np.ravel(Theta)))\n",
    "\n",
    "Ymean = np.zeros((movies, 1))  \n",
    "Ynorm = np.zeros((movies, users))\n",
    "\n",
    "for i in range(movies):  \n",
    "    idx = np.where(R[i,:] == 1)[0]\n",
    "    Ymean[i] = Y[i,idx].mean()\n",
    "    Ynorm[i,idx] = Y[i,idx] - Ymean[i]\n",
    "\n",
    "fmin = minimize(fun=cost, x0=params, args=(Ynorm, R, features, learning_rate),  \n",
    "                method='CG', jac=True, options={'maxiter': 500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 38951.84755998501\n",
       "     jac: array([ -1.62566394e-06,   2.75821570e-06,   1.91669741e-06, ...,\n",
       "        -1.39030611e-08,  -8.71059012e-08,   2.10920516e-07])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 607\n",
       "     nit: 413\n",
       "    njev: 607\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([-0.62075509, -0.03243072,  0.46170125, ...,  0.01436308,\n",
       "        0.02751417, -0.00313798])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since everything was \"unrolled\" for the optimization routine to work properly, we need to reshape our matrices back to their original dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.matrix(np.reshape(fmin.x[:movies * features], (movies, features)))\n",
    "Theta = np.matrix(np.reshape(fmin.x[movies * features:], (users, features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1682, 10), (944, 10))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Theta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our trained parameters are now in X and Theta. We can use these to create some recommendations for the user we added earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 5.],\n",
       "        [ 5.],\n",
       "        [ 5.],\n",
       "        [ 5.],\n",
       "        [ 5.],\n",
       "        [ 5.],\n",
       "        [ 5.],\n",
       "        [ 5.],\n",
       "        [ 5.],\n",
       "        [ 5.]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = X * Theta.T\n",
    "my_preds = predictions[:,-1] + Ymean\n",
    "sorted_preds = np.sort(my_preds, axis=0)[::-1]\n",
    "sorted_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us an ordered list of the top ratings, but we lost what index those ratings are for. We actually need to use argsort so we know what movie the predicted rating corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(my_preds, axis=0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movie predictions:\n",
      "Predicted rating of 5.000000000020601 for movie Great Day in Harlem, A (1994).\n",
      "Predicted rating of 5.000000000013303 for movie Prefontaine (1997).\n",
      "Predicted rating of 5.000000000012158 for movie Aiqing wansui (1994).\n",
      "Predicted rating of 5.00000000000435 for movie Saint of Fort Washington, The (1993).\n",
      "Predicted rating of 5.000000000003582 for movie Santa with Muscles (1996).\n",
      "Predicted rating of 5.000000000001924 for movie Entertaining Angels: The Dorothy Day Story (1996).\n",
      "Predicted rating of 5.000000000001799 for movie Someone Else's America (1995).\n",
      "Predicted rating of 5.000000000000307 for movie They Made Me a Criminal (1939).\n",
      "Predicted rating of 4.999999999990104 for movie Marlene Dietrich: Shadow and Light (1996) .\n",
      "Predicted rating of 4.999999999975232 for movie Star Kid (1997).\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 movie predictions:\")  \n",
    "for i in range(10):  \n",
    "    j = int(idx[i])\n",
    "    print('Predicted rating of {0} for movie {1}.'.format(str(float(my_preds[j])), movie_idx[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = Y.shape[0]  \n",
    "users = Y.shape[1]  \n",
    "features = 10  \n",
    "learning_rate = 10.\n",
    "\n",
    "X = np.random.random(size=(movies, features))  \n",
    "Theta = np.random.random(size=(users, features))  \n",
    "params = np.concatenate((np.ravel(X), np.ravel(Theta)))\n",
    "\n",
    "Ymean = np.zeros((movies, 1))  \n",
    "Ynorm = np.zeros((movies, users))\n",
    "\n",
    "for i in range(movies):  \n",
    "    idx = np.where(R[i,:] == 1)[0]\n",
    "    Ymean[i] = Y[i,idx].mean()\n",
    "    Ynorm[i,idx] = Y[i,idx] - Ymean[i]\n",
    "\n",
    "fmin = minimize(fun=cost, x0=params, args=(Y, R, features, learning_rate),  \n",
    "                method='CG', jac=True, options={'maxiter': 500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 71899.5527628886\n",
       "     jac: array([ 0.0974853 ,  0.08169711,  0.06996742, ...,  0.00685976,\n",
       "        0.00046909, -0.00366355])\n",
       " message: 'Maximum number of iterations has been exceeded.'\n",
       "    nfev: 748\n",
       "     nit: 500\n",
       "    njev: 748\n",
       "  status: 1\n",
       " success: False\n",
       "       x: array([ 1.07609152,  0.45878761,  0.50323825, ...,  0.38470338,\n",
       "        0.62884432,  0.29088375])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.matrix(np.reshape(fmin.x[:movies * features], (movies, features)))\n",
    "Theta = np.matrix(np.reshape(fmin.x[movies * features:], (users, features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1682, 10), (944, 10))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 8.50220176],\n",
       "        [ 8.49957694],\n",
       "        [ 8.34658601],\n",
       "        [ 8.25470436],\n",
       "        [ 8.19102299],\n",
       "        [ 8.1692425 ],\n",
       "        [ 8.08902451],\n",
       "        [ 8.05255828],\n",
       "        [ 8.05182372],\n",
       "        [ 8.04032994]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = X * Theta.T\n",
    "my_preds = predictions[:,-1] + Ymean\n",
    "sorted_preds = np.sort(my_preds, axis=0)[::-1]\n",
    "sorted_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(my_preds, axis=0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Titanic (1997)'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_idx[312]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 8.49957694]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_preds[312]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movie predictions:\n",
      "Predicted rating of 8.50220176470813 for movie Star Wars (1977).\n",
      "Predicted rating of 8.499576939847856 for movie Titanic (1997).\n",
      "Predicted rating of 8.346586012640152 for movie Shawshank Redemption, The (1994).\n",
      "Predicted rating of 8.254704362462345 for movie Raiders of the Lost Ark (1981).\n",
      "Predicted rating of 8.191022991944319 for movie Schindler's List (1993).\n",
      "Predicted rating of 8.169242501797461 for movie Good Will Hunting (1997).\n",
      "Predicted rating of 8.089024505999365 for movie Empire Strikes Back, The (1980).\n",
      "Predicted rating of 8.052558279317395 for movie Godfather, The (1972).\n",
      "Predicted rating of 8.051823724000272 for movie Usual Suspects, The (1995).\n",
      "Predicted rating of 8.040329941392383 for movie Wrong Trousers, The (1993).\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 movie predictions:\")  \n",
    "for i in range(10):  \n",
    "    j = int(idx[i])\n",
    "    print('Predicted rating of {0} for movie {1}.'.format(str(float(my_preds[j])), movie_idx[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mismatch between the exercise pdf and the result is an error with the pdf. Using Y instead of the correct Ynorm when calling fmin gets a match to the pdf. This has been corrected in the octave code, but not in the exercise pdf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
